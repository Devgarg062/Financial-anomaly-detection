
The core focus of this project was to assess the performance of our anomaly detection model through a practical, business-driven lens ğŸ’¼ğŸ”. To achieve this, we created a labeled test set by splitting the original dataset, resulting in approximately 100 to 200 samples ğŸ§ªğŸ“Š. Given that anomalies are typically much less frequent than normal data, even a single misclassified anomaly can significantly impact the modelâ€™s performance âš ï¸ğŸ“‰.

To address this challenge, we made two key strategic decisions:

1. **Diverse Anomaly Detection Techniques**: We implemented multiple anomaly detection methods, each utilizing distinct approaches ğŸ› ï¸ğŸ”¬. By combining the strengths of these models through a technique known as model averaging, we created a more robust and effective composite model. This strategy allowed us to leverage the unique advantages of each model and reduce the overall error rate ğŸ“ˆğŸ¤.

2. **Risk-Propensity Regulation with Unlabeled Data**: We applied the model's predictions on additional unlabeled data to fine-tune the risk profile of a simulated investment portfolio ğŸ¦ğŸ“‰. This custom portfolio, which consisted of equities, bonds, and commodities, outperformed three predefined benchmarks (low, medium, and high risk) ğŸ…ğŸ“Š, demonstrating the model's effectiveness and reliability in a practical setting.

These steps ensured that our anomaly detection model was not only rigorously evaluated but also tailored for real-world application, showcasing its potential in enhancing decision-making and risk management ğŸ“ˆğŸš€.
