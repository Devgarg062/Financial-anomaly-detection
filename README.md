
The core focus of this project was to assess the performance of our anomaly detection model through a practical, business-driven lens 💼🔍. To achieve this, we created a labeled test set by splitting the original dataset, resulting in approximately 100 to 200 samples 🧪📊. Given that anomalies are typically much less frequent than normal data, even a single misclassified anomaly can significantly impact the model’s performance ⚠️📉.

To address this challenge, we made two key strategic decisions:

1. **Diverse Anomaly Detection Techniques**: We implemented multiple anomaly detection methods, each utilizing distinct approaches 🛠️🔬. By combining the strengths of these models through a technique known as model averaging, we created a more robust and effective composite model. This strategy allowed us to leverage the unique advantages of each model and reduce the overall error rate 📈🤝.

2. **Risk-Propensity Regulation with Unlabeled Data**: We applied the model's predictions on additional unlabeled data to fine-tune the risk profile of a simulated investment portfolio 🏦📉. This custom portfolio, which consisted of equities, bonds, and commodities, outperformed three predefined benchmarks (low, medium, and high risk) 🏅📊, demonstrating the model's effectiveness and reliability in a practical setting.

These steps ensured that our anomaly detection model was not only rigorously evaluated but also tailored for real-world application, showcasing its potential in enhancing decision-making and risk management 📈🚀.
